{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fa365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb40c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Path to your main dataset folder (adjust this path!)\n",
    "# Make sure 'TrashType_Image_Dataset' is the folder containing your 'cardboard', 'glass', etc. subfolders.\n",
    "DATA_DIR = 'C:/Users/Dishant/PycharmProjects/Capstone/Garbage_Collection/TrashType_Image_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e25890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions that will be used for resizing\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "TARGET_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406844a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87feed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split percentage\n",
    "VALIDATION_SPLIT = 0.2  # 20% of the data for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a4812",
   "metadata": {},
   "source": [
    "--- Data Loading and Splitting ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading data from: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae98fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "train_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int', # 'int' for integer labels (0, 1, 2...), 'categorical' for one-hot\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='training',\n",
    "    seed=42, # Set a seed for reproducibility\n",
    "    image_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "val_ds_raw = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset='validation',\n",
    "    seed=42, # Use the same seed as training for consistent split\n",
    "    image_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b1c2b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# --- IMPORTANT FIX: Get class names BEFORE mapping/caching/prefetching ---\n",
    "class_names = train_ds_raw.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf71abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic Preprocessing (Normalization) ---\n",
    "# Rescaling layer to normalize pixel values from [0, 255] to [0, 1]\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to both datasets\n",
    "train_ds = train_ds_raw.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds_raw.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cache and Prefetch for Performance ---\n",
    "# Use .cache() to keep images in memory after first epoch if dataset fits\n",
    "# Use .prefetch() to overlap data preprocessing and model execution\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verification ---\n",
    "print(\"\\n--- Dataset Information ---\")\n",
    "print(f\"Number of training batches: {len(train_ds)}\")\n",
    "print(f\"Number of validation batches: {len(val_ds)}\")\n",
    "print(f\"Detected classes: {class_names}\") # Use the 'class_names' variable directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eaf537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch to check shapes\n",
    "for image_batch, labels_batch in train_ds.take(1):\n",
    "    print(f\"Image batch shape: {image_batch.shape}\")\n",
    "    print(f\"Labels batch shape: {labels_batch.shape}\")\n",
    "    print(f\"Sample labels (first 5): {labels_batch[:5].numpy()}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
